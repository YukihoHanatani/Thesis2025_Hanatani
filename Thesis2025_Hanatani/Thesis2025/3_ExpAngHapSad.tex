\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{怒り・悲しみ・喜び間の弁別実験}
\label{chap:ExpAngHapSad}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

高齢難聴者の感情音声知覚特性を調べるために、「怒り」「悲しみ」「喜び」の3感情間のモーフィング音声を用いて、
若年健聴者と高齢者を対象にした感情弁別実験を実施した。
先行研究\cite{hanatani2023Emo}の結果を受けて、複数の単語が収録された新たな音声データベース\cite{keioESD-J}を使用した。
まず、聴覚末梢系の機能低下だけが感情知覚に与える影響を調べるために、若年健聴者には模擬難聴処理を行った音声を聴かせて、
通常音声を聴いた場合との感情知覚の相違を検討する。
次に、高齢者にも同じ通常音声を用いて実験を行い、若年健聴者の結果と比較する。

ここでは、はじめに実験刺激の作成方法と実験条件、実験手順について説明する。
その上で、若年健聴者・高齢者の実験結果をそれぞれ示し、結果を比較する。
若年健聴者が通常音声を聞いた場合、同じ若年健聴者が模擬難聴音を聞いた場合、高齢者が同じ通常音声を聞いた場合の
弁別精度を比較し、これら3つの条件の違いから、高齢者の感情知覚の特徴について調査していく。

% ------------------------------
\section{実験刺激の作成}
\label{sec:PrepareStimuli}
% ------------------------------
感情を最もよく表現する音声の抽出を行い、音声モーフィングと模擬難聴処理で実験刺激を作成した。

% ------------------------------
\subsubsection{感情音声の再分類 \textcolor{red}{付録にスクリーニング結果入れる？}}
% ------------------------------
使用した音声データベースは慶應義塾大学研究用感情音声データベース（Keio-ESD）\cite{keioESD-J}である。
このデータベースには、舞台経験のある一般人男性（32歳）1名が、20単語それぞれを47通りの感情(以下では元感情と呼ぶ)で発声した940音声に、
複数回発声の平静音声を加えて全1025音声が収録されている。
そのうち、名詞11単語（「なみ」「なま」「みどり」「ななめ」「ながめ」「あまみず」「おもなが」「あまのがわ」「あまりもの」「おぼろづきよ」「わらわれもの」）を用いることとした。

47種ある感情を話者がどの程度表現できているか、音声を聞いて本当にその感情らしく感じられるかを確かめるために、
実験者3名（著者を含む若年健聴者:日本人大学生と大学院生）で音声の再分類を行った。
47元感情・11単語の音声を全て聞き、エクマンの基本6感情（喜び・悲しみ・怒り・恐怖・嫌悪・驚き）\cite{ekman1992argument}に分類した。
この中から、「怒り」「悲しみ」「喜び」に分類された音声は176音声（11単語 $\times$ 16元感情）であった。
この3つの感情を選択した理由は、多くの研究で一般的に用いられていて、本研究のアプローチの第一歩として適していると考えたためである。

\newpage


% ------------------------------
\subsubsection{感情尺度評定と主成分分析}
% ------------------------------
抽出された176音声の感情の強さを測定するために、前述の実験者3名が基本6感情について5段階の尺度評定を行った。
評定を行った理由としては、この段階までで大まかに感情カテゴリーごとに分かれているが、「怒り」「悲しみ」「喜び」以外の感情も知覚される可能性があるためである。
その上で、全音声・実験者3名の6感情の評定値を変数として主成分分析を行った。
この結果の第1主成分（PC1）と第2主成分（PC2）の分布を図\ref{fig:PCA-Russel_AngHapSad}(a)に示す。

PC2まで、累積寄与率84\%を占めた。
この図では、図\ref{fig:PCA-Russel_AngHapSad}(b)に示すラッセルの円環モデル\cite{russell1980circumplex}内の感情語の位置となるべく近くなるように配置を調整した。
横軸をPC2、縦軸にPC1の符号を反転させたものとしている。
比較すると、PC2が快--不快の軸で、PC1の逆符号が覚醒--沈静の軸とおおまかに一致することがわかる。
また、中心から三角形の頂点に向かう線に沿うように分布している。
各単語ごとに、三角形の頂点に近く原点から離れた音声、つまり最も「怒り」「悲しみ」「喜び」らしい単語を16元感情の中から抽出した。
これで同一内容の11単語を3感情分、合計33音声をそろえた。
なお、薄い線の三角形は、抽出された音声を単語ごとに結んでいる（次のセクションで説明する1単語を除く）。


\input{Fig1_RusselPCA.tex}


% \newpage
% ------------------------------
\subsubsection{音声モーフィング}
% ------------------------------

抽出した33音声(11単語\time 3感情)について、
音声分析変換合成システムWORLD\cite{morise2016world}を用いた音声モーフィング用のGUI\cite{kawahara2024interactive}で、
感情間の中間の音声を合成した。
図\ref{fig:MorphingAligner}に、例として単語「なみ」の喜び音声と悲しみ音声のWORLDスペクトルと、モーフィングのための特徴点を示す。

まず、GUI上で図\ref{fig:MorphingAligner}左のように一方のスペクトルを表示し、音声の音響的に異なる領域の境界を手動で設定する（縦の薄い白線）。
次に、各境界線上でレベルが大きい部分に特徴点を手動で指定する。
その後、この特徴点表示を残したままもう一方のスペクトルをオーバーレイ表示させる。
そこでこれらの点を、オーバーレイ表示させたスペクトルのレベルが大きい部分に、図\ref{fig:MorphingAligner}右になるように移動させる。
その上で、モーフィング率を指定して実行すると、この2つのスペクトル間を線形補完するようにスペクトル変形がなされ合成音が生成される。
ここでは、モーフィング率が 0,20,40,50,60,80,100\%の音声を合成した(0\%, 100\%の音声も分析合成系の影響を入れ込むため、合成している)。
合成した音声を聞き、モーフィング音声の劣化がなるべく小さくなるように特徴点の位置を繰り返し調整した。
実験者3名で、3組の感情対（「怒り-悲しみ」「悲しみ-喜び」「喜び-怒り」）を分担して作業を行った。
最後に、全員が全ての合成音を聴取し、音質の確認を行った。
確認した結果、1単語「おぼろづきよ」は他の単語よりモーフィングの際の劣化が目立ち、歪みを小さくすることができなかった。
% また、感情単語として使われる状況を想像しやすいとは思えない。
そこで、残りの10単語を実験刺激として用いることとした。
これにより、10単語\time 7モーフィング率\time 3感情間の合計210音声を準備した。
\textcolor{red}{図4にその音声の配置の概念図を示す。}


% これは、恒定法で一対比較を行い感情知覚の弁別閾を求めるためである。 
% ちょうど中間の50\%の音声に対し、他のモーフィング率の音声を比較させ、どちらが指定した感情(たとえば「喜び」)に感じるかを回答させる。
% これを3組の感情対に関して11単語分作成した。


\input{Fig2_MorphingAligner.tex}