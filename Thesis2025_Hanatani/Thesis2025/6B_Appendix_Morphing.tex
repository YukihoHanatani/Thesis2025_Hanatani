%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{音声モーフィングの手続き}
\label{sec:MorphingAppendix}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
音声分析変換合成システムWORLD\cite{morise2016world}を用いた音声モーフィング用のツール群\cite{kawahara2022WORLDGUI_J,kawahara2024interactive,kawahara2024WORLDGUI}を用いて、
実験刺激音の合成を行なった。
本章では実際に行った手続きについて説明する。

%%--------------------------------------------------------------
\section{事前準備：worldHandlerを用いた音声分析と合成}
\label{sec:WORLDHandler}
%%--------------------------------------------------------------
まず、WORLDの分析用ツール（worldHandler）を用いて、音声の分析を行った。
例として、図\ref{fig:worldHandler}に単語「なみ」の喜び音声の分析結果を示す。
ここでは、モーフィングに必要なパラメタ（基本周波数・非周期性指標・スペクトル包絡）を分析し、合成音声が生成される。
まず、Read Soundボタンを押して音声を読み込む。
次に、Fo extraction ボタンを押すと基本周波数が求められる。
自動で有声音と無声音の境界が設定されるが、必要であれば、GUI上で境界を対話的に修正する。
Aperiodicity ボタンをを押すと、設定された基本周波数と有声/無声境界に基づいて非周期性指標が計算される。
Spectrum ボタンを押すとスペクトル包絡が求められ、Synthesis ボタンで合成音声が作成される。
最後にPlay synth ボタンで再生して確認し、分析結果と合成音声を保存する。


% ----------------------------------%
\begin{figure}[h]
  \vspace{10pt}
  \centering
  \includegraphics[width = 1\columnwidth]{Figure/Appendix/6B/worldHandler_GUI_nami_hap.eps} 
  \caption{
    WorldHandlerの操作画面
    }
  \label{fig:worldHandler}
\end{figure}
% ----------------------------------%


% from kawahara2022WORLDGUI_J
% 3.1 worldHandler
% 図1に worldHandler の GUI の例を示す。
% 左側のパネルには、 操作用のボタンなどが配置されている。右側のパネルは、情報 の可視化用である。
% 左側パネルの最上段の Read Sound ボタンのクリックにより、 音声ファイルを選択して読み込む。
% MATLAB の音声ファイル 読み込み用の関数がサポートしている全ての種類のファイルを 読み込むようにしている。
% 次の段の Fo extraction ボタンのクリックにより、基本周波数が求められる。
% WORLD のピッチ抽出器である Harvest は、音 声分析合成の際の品質劣化を避けることを狙い、有声音と判断 する割合が高く設定されている。
% 目的によっては、この偏りは 不都合であるため、この GUI には、有声/無声境界を対話的に 修正する機能を加えてある。
% また、求められた基本周波数の軌 跡を手作業によって修正することも可能にしている。
% このボタ ンの直下の UNDO と REDO は、間違いの取り消しとやり直し のために用意した。
% その下の Play original と、さらにその下の Play Voiced と PlayUV は、有声/無声境界を試聴で確認するた めに用意した。
% その下の Aperiodicity ボタンをクリックすると、設定された 基本周波数と有声/無声境界に基づいて、非周期性指標が計算 される。
% 同時に、その下の Spectrum ボタンが使用可能になる。 
% Spectrum ボタンのクリックによりスペクトル包絡が求められ、 その下の Synthesis ボタンが使用可能になる。
% Synthesis ボタンのクリックにより合成音声が作成され、以 下のボタンで再生し、分析結果をファイルとして格納すること ができるようになる。
% MATLAB のグラフには、拡大や移動、読み出しの機能が既 定値として用意されている。
% この GUI でもそれらの機能を利 用できる。
% また、MATLAB のグラフ間の軸の連動機能を設定 してあり、
% 基本周波数、波形、スペクトル包絡のいずれのグラ フで時間軸に対して行った操作も他のグラフを連動して変化さ せる。
% なお、原音声も合成音声も、グラフが拡大表示されてい る場合には、グラフとして見えている部分に対応する音だけが 再生される。

\clearpage

%%--------------------------------------------------------------
\section{morphingAlignerを用いた音声間の対応付け}
\label{sec:morphingAligner}
%%--------------------------------------------------------------
worldHandlerで出力したmatファイルを読み込み、2つの音声間の対応を調整する。
図\ref{fig:morphAli}では単語「なみ」の喜び音声と悲しみ音声の調整を行っている。
なお、図\ref{fig:MorphingAligner}はこれらのスペクトル部分のみを切り取った画像である。
(a)は単語「なみ」の喜び音声、(b)は悲しみ音声、(c)はそれら2つをオーバーレイ表示させたスペクトログラムを示す。


まず、(a)の喜び音声のスペクトルでを表示し、音声の音響的に異なる領域の境界を手動で設定する（縦の薄い白線）。
次に、各境界線上でレベルが大きい部分に特徴点を手動で指定する（白点）。
スペクトル画像の左上にあるAlphaのスライダーを0.5にして、もう一方の悲しみ音声のスペクトルをオーバーレイ表示させる。
悲しみ音声のスペクトルが喜び音声のスペクトルになるべく一致するように、白線と特徴点を動かして調整する。
これにより、時間方向と周波数方向の違いを小さくする。
これらの図は、すべて調整が終わった後の状態を示している。
目印として、設置した白線と白点の位置が同一であることが分かる。
Synthesis ボタンと、Mrと書かれたスライダー（スペクトル画像の左下）により、整列された2つの音声のパラメタをスライダーに示された比率で混合して、
モーフィング音声を合成する。
ここで合成した音声を何度も聞き、モーフィング音声の劣化がなるべく小さくなるように特徴点の位置を繰り返し調整した。
最後にSave Parameterボタンによりパラメタを保存する。



% ----------------------------------%
\begin{figure}[t]
  \vspace{-50pt}
  \centering

  \begin{tabular}{ccc}
  \begin{minipage} {0.8\hsize}
  \centering
  \includegraphics [ width = 1\columnwidth]{Figure/Appendix/6B/MorphAli_hap.eps}
  \subcaption{}
  \end{minipage}\\
  
  \begin{minipage} {0.8\hsize}
  \centering
  \includegraphics [ width = 1\columnwidth]{Figure/Appendix/6B/MorphAli_sad.eps}
  \subcaption{}
  \end{minipage}\\

  \begin{minipage} {0.8\hsize}
  \centering
  \includegraphics [ width = 1\columnwidth]{Figure/Appendix/6B/MorphAli_50.eps}
  \subcaption{}
  \end{minipage} 
  
  \end{tabular}
  
  \caption{morpfhingAlignerの作業画面。2つの音声間の対応が調整された後の状態を示す。
           (a)単語「なま」の喜び音声、(b)単語「なま」の悲しみ音声、(c)a,bの2つを透明度50\%で重ね合わせたもの。
          }
  \label{fig:morphAli} 

\end{figure}
% ----------------------------------%

% 3. 3 morphingAligner
% 図 3 に、二つの事例間の対応の調整を支援するツールである morphingAligner の GUI を示す。
% これらのスナップショットは、 対応が調整された後の状態を示している。
% (a) が、固定して表示 されるスペクトログラムと、その上に配置された目印を示す。 
% この例では男性による音声を固定されるものとして用いた。こ こでは Reference と名づけている。
% (b) は、時間軸と時間周波数 上の点を操作して変形されたスペクトログラムを示している。 
% この例では女性による音声を変形されるものとして用いた。こ こでは、Target と名づけている。
% (c) は、スペクトログラムの透 明度を調整して、同じ透明度で重ねたものである。
% 目印として 設置した白線と白円の位置が同一であることが分かる。
% 実際の操作は、Reference と Target のパラメタを読み込んで、 同じ透明度で重ねた状態で、時間方向の目印を逐次的に増やし ながら位置を調整し、
% 左側のグラフで示されている二つのスペ クトログラムの距離が減少するようにすることを繰り返すこと から始める。
% 次に、位置の調整が終わったところで、両方の音 声の背景にある声道長の違いを左上のスライダーによって調整 する。
% こうして、時間軸と声道長比の調整が終わったところで、 周波数方向の細かな違いを、目印を設定し位置を調整すること で、
% さらに二つのスペクトログラムの違いが減少するように調 整する。
% この調整結果をファイルに記録し、読み込んで再開す るためのボタンを用意している。
% Synthesis ボタンと、Mr と書 かれたスライダーにより、整列された二つの事例のパラメタを、スライダーに示された比率で混合して、
% モーフィング音声を合成する。
% 二事例間のモーフィングの場合、割合を 0.5 とした場合が、二 つの事例のパラメタの整列の悪さの影響が最も大きく現れる。 
% そのため、適切な整列の支援を目的とするこのツールでは、全 てのパラメタを同一の混合比で設定している。
% 拡張されたモーフィングには、このような制約はない。
% それ ぞれの音声パラメタの時刻毎にそれぞれ異なった混合割合を設 定することが可能なように構成されている。
% また、そのための 合成関数も用意している。問題は、設定の自由度が大きいため、 どのように操作することができるようにするか、適切な概念を 設定しツールとして実装することが難しいことにある。

\clearpage

%%--------------------------------------------------------------
\section{morphingSoundGeneratorを用いた音声合成}
\label{sec:morphingSoundGenarator}
%%--------------------------------------------------------------
morphingSoundGenaratorを用いると、モーフィングを行うパラメタの指定やモーフィング率を設定して一括で音声を合成できる。
実際の作業画面を図\ref{fig:MSG}に示す。

まず、morpfhingAlignerで出力された「なみ」の喜び音声と悲しみ音声のぞれぞれのオブジェクトファイルを読み込み、SYNTHESISボタンで合成する。
今回はMorphing rate settingを "connected" に設定し、全てのパラメタ（周波数軸、時間軸、スペクトルレベル、基本周波数、非周期性指標）に関して同じ比率でモーフィングを行う。
次にモーフィングの端点を設定する。
今回はモーフィング率を0から100\%に設定するため、 whole morphing rate のスライダーを一番左の0にし、ASSIGN Aボタンを押す。
そして、スライダーを1にしてASSIGN Bボタンを押すことで反対側の端点を設定する。
右にあるstepsを11に設定してGENERATEボタンを押すと、モーフィング率が0,10,20,30,40,50,60,70,80,90,100\%の音声が出力される。
弁別実験では、このうちモーフィング率が 0,20,40,50,60,80,100\%の音声を使用した。

% ----------------------------------%
\begin{figure}[h]
  \vspace{10pt}
  \centering
  \includegraphics[width = 1\columnwidth]{Figure/Appendix/6B/MSG.eps} 
  \caption{
    morphingSoundGenaratorの操作画面
    }
  \label{fig:MSG}
\end{figure}
% ----------------------------------%

%　本文より
% まず、GUI上で図\ref{fig:MorphingAligner}左のように一方のスペクトルを表示し、音声の音響的に異なる領域の境界を手動で設定する（縦の薄い白線）。
% 次に、各境界線上でレベルが大きい部分に特徴点を手動で指定する。
% その後、この特徴点表示を残したままもう一方のスペクトルをオーバーレイ表示させる。
% そこでこれらの点を、オーバーレイ表示させたスペクトルのレベルが大きい部分に、図\ref{fig:MorphingAligner}右になるように移動させる。
% その上で、モーフィング率を指定して実行すると、この2つのスペクトル間を線形補完するようにスペクトル変形がなされ合成音が生成される。
% ここでは、モーフィング率が 0,20,40,50,60,80,100\%の音声を合成した(0\%, 100\%の音声も分析合成系の影響を入れ込むため、合成している)。
% 合成した音声を聞き、モーフィング音声の劣化がなるべく小さくなるように特徴点の位置を繰り返し調整した。
% 実験者3名で、3組の感情対（「怒り--悲しみ」「悲しみ--喜び」「喜び--怒り」）を分担して作業を行った。
% 最後に、全員が全ての合成音を聴取し、音質の確認を行った。
% 確認した結果、1単語「おぼろづきよ」は他の単語よりモーフィングの際の劣化が目立ち、歪みを小さくすることができなかった。
% また、感情単語として使われる状況を想像しやすいとは思えない。

